algo: ppo
algo_config:
    training: false
    hidden_dim: 256
    use_gae: True
    max_env_steps: 5000000
    entropy_coef: 0.01

    opt_epochs: 10
    mini_batch_size: 64
    actor_lr: 0.0003
    critic_lr: 0.001

    rollout_batch_size: 4
    rollout_steps: 100

    log_interval: 1000
    save_interval: 1000
    num_checkpoints: 100
    eval_interval: 1000
    eval_save_best: True
    tensorboard: True
