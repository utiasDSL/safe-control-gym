algo: ppo
algo_config:
  actor_lr: 0.0003
  clip_obs: 10.0
  clip_param: 0.2
  clip_reward: 10.0
  critic_lr: 0.001
  deque_size: 10
  entropy_coef: 0.01
  eval_batch_size: 10
  eval_interval: 1000
  eval_save_best: true
  gae_lambda: 0.95
  gamma: 0.99
  hidden_dim: 64
  log_interval: 1000
  max_env_steps: 30000
  max_grad_norm: 0.5
  mini_batch_size: 64
  norm_obs: false
  norm_reward: false
  num_checkpoints: 0
  num_workers: 1
  opt_epochs: 10
  rollout_batch_size: 4
  rollout_steps: 100
  save_interval: 1000
  target_kl: 0.01
  tensorboard: false
  use_clipped_value: false
  use_gae: true
device: cpu
func: train
kv_overrides:
- task_config.ctrl_freq=10
- task_config.pyb_freq=1000
output_dir: temp-data/figure8
overrides:
- safe_control_gym/configs/overrides/ppo_cartpole.yaml
restore: null
seed: 2
tag: filter/ppo2
task: cartpole_new
task_config:
  constraints: null
  cost: rl_reward
  ctrl_freq: 10
  done_on_violation: false
  gui: false
  inertial_prop: null
  inertial_prop_randomization_info: null
  info_in_reset: true
  init_state: null
  init_state_randomization_info: null
  normalized_rl_action_space: false
  pyb_freq: 1000
  randomized_inertial_prop: false
  randomized_init: true
  seed: null
  task: stabilization
  task_info: null
  verbose: false
