  algo: gp_mpc
  algo_config:
    horizon: 25
    q_mpc: [1, 1, 1, 1, 1]
    r_mpc: [0.1]
    gp_model_path: null
    train_iterations: 500
    test_data_ratio: 0.2
    soft_constraints: null
    optimization_iterations:
      - 3000
      - 3000
      - 3000
      - 3000
      - 3000
      - 3000
    learning_rate:
      - 0.01
      - 0.01
      - 0.01
      - 0.01
      - 0.01
      - 0.01
    normalize_training_data: False
    prior_info:
      prior_prop:
        M: 0.027
        Iyy: 1.4e-05
    initial_rollout_std: 0.0
    prior_param_coeff: 1.5
    prob: 0.95
    warmstart: True
    gp_approx: 'mean_eq' # 'taylor'
    sparse_gp: true
    n_ind_points: 40
    inducing_point_selection_method: 'kmeans'
    overwrite_saved_data: false
    online_learning: False
    additional_constraints: null
    input_mask: null
    target_mask: null
    num_epochs: 5
    num_samples: 75
    num_test_episodes_per_epoch: 2
    num_train_episodes_per_epoch: 2
    same_test_initial_state: true
    same_train_initial_state: false
    rand_data_selection: false
    terminate_train_on_done: True
    terminate_test_on_done: True
    parallel: True